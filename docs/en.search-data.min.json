[{"id":0,"href":"/documentation_cytech_google_cloud_computing/manual_configuration/tensorflow/","title":"Installation de tensorflow","parent":"Configuration manuelle de la machine virtuelle","content":"Commençons par la librairie Cuda qui permettra à Tensorflow d\u0026rsquo;utiliser le GPU.\ninstallation de Cuda Clikez sur le bouton ssh afin d\u0026rsquo;ouvrir un terminal sur votre machine virtuelle.\nSélectionner un mode de téléchargement sur le site de cuda. A l\u0026rsquo;heure actuelle, tensorflow a été compilé avec la version 11.0 de cuda. Nous choisirons donc cette version.\n  Ensuite, exécutez donc les commandes suivantes:\nsudo apt udpate wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu2004-11-0-local_11.0.2-450.51.05-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2004-11-0-local_11.0.2-450.51.05-1_amd64.deb sudo apt-key add /var/cuda-repo-ubuntu2004-11-0-local/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda Ajoutez les lignes suivantes dans le fichier ~/.bashrc\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64export\u0026quot; export PATH=$PATH:/usr/local/cuda/bin/\u0026quot; Puis exécutez la commande suivante:\nsource .bashrc Ensuite, installez cudnn. Il vous sera demandé de créer un compte. Une alternative est de le télécharger directement à partir de ce lien (ATTENTION, cette version n\u0026rsquo;est pas mise à jour):\nwget put the link sudo dpkg -i libcudnn8_8.0.5.39-1+cuda11.0_amd64.deb sudo dpkg -i libcudnn8-dev_8.0.5.39-1+cuda11.0_amd64.deb Pour vérifier que l\u0026rsquo;installation a fonctionné, nous pouvons tester la commande nvidia-smi:\n$ nvidia-smi Wed Feb 3 10:20:31 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 460.32.03 Driver Version: 460.32.03 CUDA Version: 11.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K80 Off | 00000000:00:04.0 Off | 0 | | N/A 71C P8 35W / 149W | 13MiB / 11441MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 937 G /usr/lib/xorg/Xorg 8MiB | | 0 N/A N/A 1081 G /usr/bin/gnome-shell 3MiB | +-----------------------------------------------------------------------------+ Une information intéressante est la quantité de mémoire occupée 12MiB / 11441MiB. Cette information est utile lorsque nous entraînons nos modèles et pour vérifier si notre gpu est utilisé ou pas.\nEnvironnement Anaconda  Récupérez l\u0026rsquo;installeur d\u0026rsquo;Anaconda sur la page des téléchargements. Choisissez celui pour linux en 64 bits et téléchargez-le, par exemple avec:  wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh  bash Anaconda3-5.1.0-Linux-x86_64.sh Il est ok d\u0026rsquo;utiliser les défauts et d\u0026rsquo;accepter l\u0026rsquo;initialisation  Do you wish the installer to initialize Anaconda3 by running conda init? [yes|no] [no] \u0026gt;\u0026gt;\u0026gt; yes   Redémmarez votre shell ou rechargez votre fichier source ~/.bashrc\n  Installez tensorflow depuis votre environnement conda\n  (base) pandregay@instance-1:~$ pip install tensorflow  Testez que tensorflow a accès à votre gpu:  import tensorflow as tf physical_devices = tf.config.list_physical_devices(\u0026#39;GPU\u0026#39;) Put the result of the command  "},{"id":1,"href":"/documentation_cytech_google_cloud_computing/docker/","title":"tensorflow and Jupyter in Docker","parent":"Usage de Google Cloud Computing","content":""},{"id":2,"href":"/documentation_cytech_google_cloud_computing/utilisation/transfert_fichier/","title":"Transfert de fichiers","parent":"Utilisation de la VM","content":"connection en ssh Uploadez des fichiers sur sa machine locale  Par ssh   Ajout de la clé publique SUR VOTRE MACHINE PERSONNELLE : * copier l\u0026rsquo;intégralité du fichier ~/.ssh/id_rsa.pub (le créer avec la commande ssh-keygen s\u0026rsquo;il n\u0026rsquo;existe pas) * le coller SUR LA MACHINE GCP dans le fichier ~/.ssh/authori\n  Ensuite, pour copier MON_FICHIER de la machine locale vers la VM scp /chemin/vers/MON_FICHIER login@address_ip_externe:/chemin/sur/la/VM\n  buckets "},{"id":3,"href":"/documentation_cytech_google_cloud_computing/manual_configuration/jupyter/","title":"Jupyter notebook","parent":"Configuration manuelle de la machine virtuelle","content":"Jupyter notebook : option1 : tunnel ssh Il existe plusieurs manières, nous décrivons ici l\u0026rsquo;utilisation d\u0026rsquo;un tunnel ssh:\nAjout de la clé publique. Il faut d\u0026rsquo;abord configurer votre serveur pour qu\u0026rsquo;il accepte des connections venant de votre ordinateur. Pour cela, copiez votre clé publique sur le serveur\n Dans \u0026ldquo;Compute Engine -\u0026gt; Instance de VM -\u0026gt; Métadonnées\u0026rdquo; Séléctionnez l\u0026rsquo;onglet \u0026ldquo;Clés SSH\u0026rdquo; puis le bouton \u0026ldquo;Modifier\u0026rdquo;    Copiez l\u0026rsquo;intégralité du fichier ~/.ssh/id_rsa.pub Si le fichier n\u0026rsquo;existe pas, vous pouvez le générer avec la commande ssh-keygen\nÀ présent, ouvrez un tunnel ssh connectant votre machine à votre VM.\nssh -X -L 8099:localhost:8099 pandregay@adresse_ip_externe Depuis la VM, lancez votre jupyter:\njupyter-notebook --no-browser --port=8099 ... To access the notebook, open this file in a browser: file:///home/pandregay/.local/share/jupyter/runtime/nbserver-18405-open.html Or copy and paste one of these URLs: http://localhost:8099/?token=2703d92e3badf239641b349d2f5c4e9828cf3968f3c0926c  Dans ce cas, vous accédez à votre notebook en copiant l\u0026rsquo;adresse\nhttp://localhost:8099/?token=2703d92e3badf239641b349d2f5c4e9828cf3968f3c0926c dans votre navigateur.\nL\u0026rsquo;url que vous entrez dans le navigateur doit avoir la forme : http://adresse_ip_externe:8889/?token=votre_token\nJupyter noteboook option2 : configuration des pare-feu et addresse IP static Configuration des firewalls pour Jupyter Sur le site de Google Cloud platform, allez dans Réseaux VPC, \nCréer une IP externe addresse IP Externe :\n Passez de éphémère à static Mettre un nom sur l\u0026rsquo;addresse IP  Ajouter une règle firewall Dans pare-feu  Vérifiez default-allow-ssh =\u0026gt; tcp:22 Dans cible choissisez \u0026ldquo;toutes les instances du réseau\u0026rdquo; Dans plage d\u0026rsquo;adresse IP : 0.0.0.0/0 Protocole et port spécifié: TCP 22: 8889  installation de jupyter sur la VM  jupyter notebook --ip=0.0.0.0 --port=8889 --no-browser \u0026amp;  Accéder au Jupyter :\n copier l\u0026rsquo;adresse à partir de \u0026ldquo;?token=\u0026hellip;..\u0026rdquo; Ajouter devant le \u0026ldquo;?\u0026rdquo; l\u0026rsquo;adresse externe de votre VM (dans instance VM) et :8889.n  L\u0026rsquo;url que vous entrez dans le navigateur doit avoir la forme : http://adresse_ip_externe:8889/?token=votre_token\n"},{"id":4,"href":"/documentation_cytech_google_cloud_computing/pre_configured_vm/","title":"Machine virtuelle pré-configurée","parent":"Usage de Google Cloud Computing","content":"Il est possible d\u0026rsquo;installer une VM pré-configurée contenant Cuda, tensorflow, et la plupart des librairies utiles pour le Deep learning.\nhttps://console.cloud.google.com/ai/platform/notebooks/list/instances\nSelect 1 gpu tesla\nCocher la case \u0026ldquo;Install NVIDIA GPU driver automatically for me\u0026rdquo;\nPricing de la VM dans ce cas, ce qui coûte c\u0026rsquo;est la VM quand elle tourne, et les deux disks de 100Go. Du coup pour stopper sans perdre les données vous pouvez faire un snapshot des disks https://console.cloud.google.com/compute/disks et éteindre la VM. Pour reprendre il faudra cliquer sur le snapshot https://console.cloud.google.com/compute/snapshots pour recréer un disk à partir de lui. Ensuite depuis l\u0026rsquo;instance faudra désigner les deux disks (Mais sinon vous pouvez tout supprimer, et réimporter quand nécessaire)\n"},{"id":5,"href":"/documentation_cytech_google_cloud_computing/utilisation/","title":"Utilisation de la VM","parent":"Usage de Google Cloud Computing","content":""},{"id":6,"href":"/documentation_cytech_google_cloud_computing/troubleshooting/","title":"Troubleshooting","parent":"Usage de Google Cloud Computing","content":"Problème de quotas  Passez la limite de \u0026ldquo;Compute Engine API GPUs (all regions)\u0026rdquo; à 1:\n IAM et admin =\u0026gt; quotas Cliquez le champ Filter table -\u0026gt; limit name -\u0026gt; faites déroulez la liste jusqu\u0026rsquo;à trouver GPU all regions. Sélectionnez-le, un bandeau doit apparaître à droite de l\u0026rsquo;écran. Cliquez \u0026ldquo;global\u0026rdquo; éditez les quotas  faire une demande pour le passer à 1. (parfois 15 min d\u0026rsquo;attente avant confirmation)  "},{"id":7,"href":"/documentation_cytech_google_cloud_computing/categories/","title":"Categories","parent":"Usage de Google Cloud Computing","content":""},{"id":8,"href":"/documentation_cytech_google_cloud_computing/manual_configuration/","title":"Configuration manuelle de la machine virtuelle","parent":"Usage de Google Cloud Computing","content":" Troubleshoot : Aucune GPU listée :   pip3 show tensorflow-gpu Vérifier que tensorflow-gpu==2.2.0 est installé sur l\u0026rsquo;environnement conda où vous lancez le jupyter. Cette commande doit retourner la version 2.2 (voir au dessus, pour correspondre au cuda10.2 c\u0026rsquo;est nécessaire de pas mettre la dernière version dispo)\n  pip3 show tensorflow Cette commande ne devrait rien retourner, dans ce cas c\u0026rsquo;est OK\n  Si lorsque vous listez les devices (avec la cellule d\u0026rsquo;au dessus) vous voyez dans la console : Could not load dynamic library \u0026lsquo;libcudart.so.10.2\u0026rsquo; alors il faut hacker le code tensorflow pour qu\u0026rsquo;il la trouve (ou réinstaller depuis les sources, c\u0026rsquo;est ce qu\u0026rsquo;ils disent sur le tuto mais c\u0026rsquo;est embêtant) * sudo ln -s /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2 /usr/lib/x86_64-linux-gnu/libcudart.so.10.2\n  S\u0026rsquo;il demande une autre version de la librairie libcudart alors c\u0026rsquo;est qu\u0026rsquo;il faut que vous changiez la version de tensorflow-gpu pour qu\u0026rsquo;il change ses prérequis\n  Si toujours pas bon, ajoutez ça à la fin du bashrc : * export PATH=/usr/local/cuda-10.2/bin${PATH:+:${PATH}} * export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n  Ca fonctionnera quand la cellule vous printera une ligne pour le CPU et une ou plusieurs lignes pour la GPU\nTroubleShooting Augmenter les quotas Passez la limite de \u0026ldquo;Compute Engine API GPUs (all regions)\u0026rdquo; à 1:\n Dans la barre de recherche : \u0026ldquo;Recherchez des produits et des ressoures\u0026rdquo;, tapez IAM et admin Dans le menu de gauche, allez dans \u0026ldquo;quotas\u0026rdquo; Cliquez le champ Filter table -\u0026gt; limit name -\u0026gt; faites déroulez la liste jusqu\u0026rsquo;à trouver GPU all regions. Sélectionnez-le, un bandeau doit apparaître à droite de l\u0026rsquo;écran. Cliquez \u0026ldquo;global\u0026rdquo; éditez les quotas  Faire une demande pour le passer à 1. (parfois 15 min d\u0026rsquo;attente avant confirmation par mail)  "},{"id":9,"href":"/documentation_cytech_google_cloud_computing/docker/docker/","title":"Running docker on tensorflow","parent":"tensorflow and Jupyter in Docker","content":"Étant donné l\u0026rsquo;usage actuel universel de docker, c\u0026rsquo;est probablement une bonne idée de prendre du temps pour effectuer cette installation.\nVous devez avoir au préablable créé votre VM.  A few lines to explain how docker is working Installez docker sur votre VM\nInstallation de l\u0026rsquo;image Installation des drivers nvidia: Récupérer la dernière version sur le site de nvidia\nsudo apt-get install ubuntu-drivers-common ubuntu-drivers devices  == /sys/devices/pci0000:00/0000:00:04.0 == modalias : pci:v000010DEd0000102Dsv000010DEsd0000106Cbc03sc02i00 vendor : NVIDIA Corporation model : GK210GL [Tesla K80] driver : nvidia-driver-450-server - distro non-free driver : nvidia-driver-460 - distro non-free recommended driver : nvidia-driver-390 - distro non-free driver : nvidia-driver-418-server - distro non-free driver : nvidia-driver-450 - distro non-free driver : xserver-xorg-video-nouveau - distro free builtin  Nous installons la version recommandée (ici la 460):\nsudo apt install nvidia-driver-460 Installation du container nvidia Créer un fichier nvidia-container-runtime-script.sh avec le contenu suivant:\ncurl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \\ sudo apt-key add - distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list sudo apt-get update Puis installez le conteneur nvidia\nsudo apt-get install nvidia-container-runtime sudo systemctl restart docker Re-démarrez votre machine.\nInstallation de l\u0026rsquo;image docker Des fichiers docker sont disponibles sur le github de tensorflow:\nsudo apt update sudo apt install git git clone https://github.com/tensorflow/tensorflow.git cd tensorflow/tensorflow/tools/dockerfiles/ sudo docker build -f ./dockerfiles/gpu-jupyter.Dockerfile -t tf . sudo docker run -it --gpus all --rm -v $(realpath ~/notebooks):/tf/notebooks -p 8888:8888 tf:latest It is more simple to download directly from the run command, but then, you don\u0026rsquo;t have the\nsudo docker run -it --gpus all --rm -v $(realpath ~/notebooks):/tf/notebooks -p 8888:8888 tf:latest   "},{"id":10,"href":"/documentation_cytech_google_cloud_computing/tags/","title":"Tags","parent":"Usage de Google Cloud Computing","content":""},{"id":11,"href":"/documentation_cytech_google_cloud_computing/","title":"Usage de Google Cloud Computing","parent":"","content":""},{"id":12,"href":"/documentation_cytech_google_cloud_computing/manual_configuration/vm_creation/","title":"VM creation","parent":"Configuration manuelle de la machine virtuelle","content":"Dans cette partie, nous allons installé une machine google cloud\nCréer l\u0026rsquo;instance du serveur Google Cloud Création de la VM  Compute engine =\u0026gt; instance VM =\u0026gt; Créer Région : Europe-west1 (Belgique) Zone : europe-west1-b Config de machine =\u0026gt; Série : N1 Type de machine : n1-standard-8 (30go)  Dans la liste déroulange \u0026ldquo;Plate-forme du processeur et GPU\u0026rdquo;\n  Ajouter un GPU : NVIDIA Tesla K80\n  Image ubuntu 20.04 avec un disque dur de 200Go\n  Cocher Autoriser le trafic HTTP et HTTPS\n  Reportez-vous à Augmenter les quotas si vous rencontrez le message d\u0026rsquo;erreur \u0026ldquo;\u0026hellip; does not have enough resources available to fulfill the request. Try a different zone, or try again later. \u0026quot;  Vous avez créer votre VM avec son adresse IP externe qui vous servira pour vous y connecter.\nÀ présent, il s\u0026rsquo;agit d\u0026rsquo;y installer les librairies nous permettant d\u0026rsquo;y entraîner nos réseaux. Ici deux possibilités, un docker, ou une installation manuelle des librairies Cuda, tensorflow.\n"}]